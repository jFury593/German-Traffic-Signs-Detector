{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 **Logistic regression using Scikit-learn** \n",
    "\n",
    "##  Logistic regression\n",
    "\n",
    "Logistic regression is named for the function used at the core of the method, the logistic function. In linear regression, the outcome (dependent variable) is continuous. It can have any one of an infinite number of possible values. In logistic regression, the outcome (dependent variable) has only a limited number of possible values. Logistic Regression is used when response variable is categorical in nature.\n",
    "\n",
    "### Logistic regression in Scikit-learn architecture:\n",
    "```\n",
    "Tolerance for stopping criteria = 0.0001\n",
    "Maximum number of iterations = 1000\n",
    "\n",
    "```\n",
    "Number of inputs = 1024, that correspond to the flatten image.\n",
    "\n",
    "Number of outputs = 43, thath correspond to each class.\n",
    "```\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Model Training and Evaluation\n",
    "\n",
    "For **model 1** we have to put the following comand:\n",
    "```\n",
    "python app.py train -m model_1 -d images/train\n",
    "```\n",
    "The output will be the accuracy of model 1:\n",
    "```\n",
    "Model is logistic regression with scikit-learn\n",
    "Train accuracy of model 1 is: 85.77405857740585\n",
    "```\n",
    "We've been able to reach a maximum accuracy of **85.77%** on the validation set.\n",
    "\n",
    "---\n",
    "\n",
    "### Testing the Model using the Test Set\n",
    "\n",
    "For **model 1** we have to put the following comand:\n",
    "```\n",
    "python app.py test -m model_1 -d images/test\n",
    "```\n",
    "The output will be the accuracy of model 1:\n",
    "```\n",
    "Model is logistic regression with scikit-learn\n",
    "Test accuraccy of model 1 is: 89.03654485049833\n",
    "```\n",
    "We've been able to reach a maximum accuracy of **89.03%** on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Charge the trained model\n",
    "\n",
    "The trained model is on **'models\\model1\\saved'** the name of the model file is: **log_reg_sci(model_1).p **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X_validation  # images for test model\n",
    "X_validation = []\n",
    "global y_validation   # label for validation data\n",
    "y_validation = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load The test set to test the model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_test_data():\n",
    "    # Open csv of the test folder and save the data to X_test and y_test\n",
    "    path = '../images/test'\n",
    "    with open(path+'/test_file.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=';')\n",
    "        for row in readCSV:          \n",
    "            im = cv2.imread(path+'/'+str(row[0]),0)\n",
    "            im = cv2.resize(im, (32, 32))            \n",
    "            global X_validation\n",
    "            X_validation.append(im)\n",
    "            global y_validation\n",
    "            y_validation.append(int(row[1]))\n",
    "\n",
    "    X_validation = preprocess(X_validation,\"Validation dataset\")\n",
    "    X_validation = np.array(X_validation)         #Convert to numpy array\n",
    "    y_validation = np.array(y_validation)         #Convert to numpy array  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preprocess the images\n",
    "\n",
    "In this step, we will apply several preprocessing steps to the input images to achieve the best possible results.\n",
    "\n",
    "**We will use the following preprocessing techniques:**\n",
    "1. Grayscaling.\n",
    "2. Local Histogram Equalization.\n",
    "3. Normalization.\n",
    "\n",
    "**1. Grayscaling**: I use `OpenCV` to convert the training images into grey scale.\n",
    "\n",
    "**2. Local Histogram Equalization**: Spreads out the most frequent intensity values in an image, resulting in enhancing images with low contrast. \n",
    "\n",
    "**3. Normalization**: Normalization is a process that changes the range of pixel intensity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.morphology as morp\n",
    "from skimage.filters import rank\n",
    "\n",
    "def local_histo_equalize(image):\n",
    "    \"\"\"\n",
    "    Apply local histogram equalization to grayscale images.\n",
    "        Parameters:\n",
    "            image: A grayscale image.\n",
    "    \"\"\"    \n",
    "    kernel = morp.disk(30)\n",
    "    img_local = rank.equalize(image, selem=kernel)\n",
    "    return img_local\n",
    "\n",
    "def image_normalize(image):\n",
    "    \"\"\"\n",
    "    Normalize images to [0, 1] scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    image = np.divide(image, 255)\n",
    "    return image\n",
    "\n",
    "def preprocess(dataset,text):    \n",
    "    global sample_idx   # For plot porpose\n",
    "    sample_idx = np.random.randint(len(dataset), size=18)  \n",
    "    # Local Histogram Equalization \n",
    "    equalized_images = list(map(local_histo_equalize, dataset))\n",
    "    # Normalization \n",
    "    normalized_images = list(map(image_normalize, equalized_images))\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model 1 with images from test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_test_data()\n",
    "global X_validation    \n",
    "# Convert shape of input (856x32x32) to (856x1024)\n",
    "nsamples, nx, ny = X_validation.shape\n",
    "X_validation = X_validation.reshape((nsamples,nx*ny))  #Reshape X_train: 853x32x32 to 853x1024\n",
    "\n",
    "# load the model from folder model1/saved/\n",
    "loaded_model = pickle.load(open('../models/model1/saved/log_reg_sci(model_1).p', 'rb'))    \n",
    "predicted = loaded_model.predict(X_validation)\n",
    "print(\"Test accuraccy of model 1 is: \"+str(accuracy_score(y_validation, predicted)*100))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
